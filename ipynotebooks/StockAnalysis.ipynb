{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d493ca62-d7a9-44fc-a427-e99c6dc9d398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol             Security             GICS Sector  \\\n",
       "0    MMM                   3M             Industrials   \n",
       "1    AOS          A. O. Smith             Industrials   \n",
       "2    ABT  Abbott Laboratories             Health Care   \n",
       "3   ABBV               AbbVie             Health Care   \n",
       "4    ACN            Accenture  Information Technology   \n",
       "\n",
       "                GICS Sub-Industry    Headquarters Location  Date added  \\\n",
       "0        Industrial Conglomerates    Saint Paul, Minnesota  1957-03-04   \n",
       "1               Building Products     Milwaukee, Wisconsin  2017-07-26   \n",
       "2           Health Care Equipment  North Chicago, Illinois  1957-03-04   \n",
       "3                   Biotechnology  North Chicago, Illinois  2012-12-31   \n",
       "4  IT Consulting & Other Services          Dublin, Ireland  2011-07-06   \n",
       "\n",
       "       CIK      Founded  \n",
       "0    66740         1902  \n",
       "1    91142         1916  \n",
       "2     1800         1888  \n",
       "3  1551152  2013 (1888)  \n",
       "4  1467373         1989  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install yfinance pandas lxml matplotlib pandas_market_calendars --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "from pandas_market_calendars import get_calendar \n",
    "\n",
    "# Step 1: Get the SnP 500 Tickers from Wikipedia\n",
    "\n",
    "payload=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "constituents_table = payload[0]\n",
    "df = constituents_table\n",
    "\n",
    "# Some ticker symbols contain periods (e.g., BRK.B), which Yahoo Finance expects as a dash (BRK-B)\n",
    "tickers = df['Symbol'].str.replace('.', '-', regex=False).tolist()\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c3f35f9-d03b-4a70-b288-55dc1caa6c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                            Open        High         Low       Close  \\\n",
      "Datetime                                                                    \n",
      "2025-02-06 09:30:00-05:00  231.339996  233.800003  230.779297  231.539993   \n",
      "2025-02-06 10:30:00-05:00  231.585007  232.325607  230.425003  231.514999   \n",
      "2025-02-06 11:30:00-05:00  231.509995  231.634995  230.899994  231.330002   \n",
      "2025-02-06 12:30:00-05:00  231.345001  232.339996  231.029999  232.190002   \n",
      "2025-02-06 13:30:00-05:00  232.190002  233.110001  232.080002  232.869995   \n",
      "2025-02-06 14:30:00-05:00  232.889999  232.889999  231.895004  232.279999   \n",
      "2025-02-06 15:30:00-05:00  232.289993  233.279999  231.929993  233.220001   \n",
      "2025-02-07 09:30:00-05:00  232.514999  234.000000  229.880005  230.389999   \n",
      "2025-02-07 10:30:00-05:00  230.339996  231.268005  228.899994  229.054993   \n",
      "2025-02-07 11:30:00-05:00  229.085007  229.419998  228.195007  228.400604   \n",
      "2025-02-07 12:30:00-05:00  228.389999  229.440002  228.363297  229.298904   \n",
      "2025-02-07 13:30:00-05:00  229.289993  229.500000  227.830002  227.880005   \n",
      "2025-02-07 14:30:00-05:00  227.889999  228.580002  227.789993  228.000000   \n",
      "2025-02-07 15:30:00-05:00  227.990005  228.149994  227.259995  227.710007   \n",
      "2025-02-10 09:30:00-05:00  229.570007  230.585007  228.800003  229.866196   \n",
      "2025-02-10 10:30:00-05:00  229.889999  229.911606  228.740005  229.360001   \n",
      "2025-02-10 11:30:00-05:00  229.370804  229.384995  228.239197  228.470703   \n",
      "2025-02-10 12:30:00-05:00  228.470001  228.880005  228.369995  228.470001   \n",
      "2025-02-10 13:30:00-05:00  228.485001  229.035004  228.404999  228.699905   \n",
      "2025-02-10 14:30:00-05:00  228.699997  228.839996  227.600006  227.690002   \n",
      "2025-02-10 15:30:00-05:00  227.695007  227.880005  227.199997  227.639999   \n",
      "2025-02-11 09:30:00-05:00  228.199997  233.490005  228.130005  233.339996   \n",
      "2025-02-11 10:30:00-05:00  233.320007  234.717896  232.820099  234.649994   \n",
      "2025-02-11 11:30:00-05:00  234.660004  235.229996  233.721695  234.572296   \n",
      "\n",
      "Price                        Volume  \n",
      "Datetime                             \n",
      "2025-02-06 09:30:00-05:00   6919081  \n",
      "2025-02-06 10:30:00-05:00   3599406  \n",
      "2025-02-06 11:30:00-05:00   2213517  \n",
      "2025-02-06 12:30:00-05:00   2393555  \n",
      "2025-02-06 13:30:00-05:00   1818718  \n",
      "2025-02-06 14:30:00-05:00   2205672  \n",
      "2025-02-06 15:30:00-05:00   3111368  \n",
      "2025-02-07 09:30:00-05:00   7814805  \n",
      "2025-02-07 10:30:00-05:00   5664232  \n",
      "2025-02-07 11:30:00-05:00   3763438  \n",
      "2025-02-07 12:30:00-05:00   3721234  \n",
      "2025-02-07 13:30:00-05:00   2602577  \n",
      "2025-02-07 14:30:00-05:00   2965606  \n",
      "2025-02-07 15:30:00-05:00   5030649  \n",
      "2025-02-10 09:30:00-05:00   6362641  \n",
      "2025-02-10 10:30:00-05:00   3755966  \n",
      "2025-02-10 11:30:00-05:00   2474012  \n",
      "2025-02-10 12:30:00-05:00   2457578  \n",
      "2025-02-10 13:30:00-05:00   1724663  \n",
      "2025-02-10 14:30:00-05:00   2971076  \n",
      "2025-02-10 15:30:00-05:00   3507517  \n",
      "2025-02-11 09:30:00-05:00  16450165  \n",
      "2025-02-11 10:30:00-05:00   7044159  \n",
      "2025-02-11 11:30:00-05:00   5739199  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define the date range for downloading data from yfinance\n",
    "end_date = dt.datetime.now()\n",
    "end_date = end_date - dt.timedelta(days=1)\n",
    "start_date = end_date - dt.timedelta(days=30)  # Adjust as needed\n",
    "\n",
    "# Step 3: Batch download Yahoo Finance data for all tickers at 1-hour intervals\n",
    "data = yf.download(\n",
    "    tickers,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    interval='1h',\n",
    "    group_by='ticker',\n",
    "    progress=False\n",
    ")\n",
    "\n",
    "# Step 4: Convert the datetime index to Eastern Time\n",
    "# If the index is na√Øve, we assume it is in UTC, then convert to America/New_York\n",
    "if data.index.tz is None:\n",
    "    data.index = data.index.tz_localize('UTC')\n",
    "data.index = data.index.tz_convert('America/New_York')\n",
    "\n",
    "# Example: Display the first few rows of AAPL\n",
    "print(data['AAPL'].head(24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cf629ed-28ac-481b-b858-19a28600b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                           Open      Close  Prev_Close\n",
      "Datetime                                                   \n",
      "2025-02-06 09:30:00-05:00  19.530001  19.459999         NaN\n",
      "2025-02-06 10:30:00-05:00  19.468399  19.366400         NaN\n",
      "2025-02-06 11:30:00-05:00  19.365000  19.280001         NaN\n",
      "2025-02-06 12:30:00-05:00  19.274401  19.370001         NaN\n",
      "2025-02-06 13:30:00-05:00  19.360001  19.254999         NaN\n",
      "2025-02-06 14:30:00-05:00  19.254999  19.285000         NaN\n",
      "2025-02-06 15:30:00-05:00  19.290001  19.379999         NaN\n",
      "2025-02-07 09:30:00-05:00  19.360001  19.145700   19.379999\n",
      "2025-02-07 10:30:00-05:00  19.145000  19.072701   19.379999\n",
      "2025-02-07 11:30:00-05:00  19.075001  19.129999   19.379999\n",
      "2025-02-07 12:30:00-05:00  19.125000  19.125000   19.379999\n",
      "2025-02-07 13:30:00-05:00  19.124701  19.075001   19.379999\n",
      "2025-02-07 14:30:00-05:00  19.078899  19.075001   19.379999\n",
      "2025-02-07 15:30:00-05:00  19.070000  19.105000   19.379999\n",
      "2025-02-10 09:30:00-05:00  19.250000  19.900101   19.105000\n",
      "2025-02-10 10:30:00-05:00  19.905001  19.719900   19.105000\n",
      "2025-02-10 11:30:00-05:00  19.719900  19.868401   19.105000\n",
      "2025-02-10 12:30:00-05:00  19.870001  19.890301   19.105000\n",
      "2025-02-10 13:30:00-05:00  19.889999  19.795000   19.105000\n",
      "2025-02-10 14:30:00-05:00  19.799000  19.764999   19.105000\n",
      "2025-02-10 15:30:00-05:00  19.769899  19.760000   19.105000\n",
      "2025-02-11 09:30:00-05:00  19.870001  20.999901   19.760000\n",
      "2025-02-11 10:30:00-05:00  21.000000  21.578699   19.760000\n",
      "2025-02-11 11:30:00-05:00  21.575001  21.270100   19.760000\n",
      "2025-02-11 12:30:00-05:00  21.275000  21.184999   19.760000\n",
      "2025-02-11 13:30:00-05:00  21.180000  21.035000   19.760000\n",
      "2025-02-11 14:30:00-05:00  21.040001  21.004999   19.760000\n",
      "2025-02-11 15:30:00-05:00  21.000000  20.990000   19.760000\n",
      "2025-02-12 09:30:00-05:00  21.950001  21.620001   20.990000\n",
      "2025-02-12 10:30:00-05:00  21.610001  21.787201   20.990000\n",
      "2025-02-12 11:30:00-05:00  21.785000  21.834600   20.990000\n",
      "2025-02-12 12:30:00-05:00  21.830000  22.110001   20.990000\n",
      "2025-02-12 13:30:00-05:00  22.115000  22.256599   20.990000\n",
      "2025-02-12 14:30:00-05:00  22.257700  22.159901   20.990000\n",
      "2025-02-12 15:30:00-05:00  22.155001  22.490000   20.990000\n",
      "2025-02-13 09:30:00-05:00  22.815001  24.334999   22.490000\n",
      "2025-02-13 10:30:00-05:00  24.330799  24.315001   22.490000\n",
      "2025-02-13 11:30:00-05:00  24.315001  24.310101   22.490000\n",
      "2025-02-13 12:30:00-05:00  24.315300  24.594999   22.490000\n",
      "2025-02-13 13:30:00-05:00  24.594999  24.674400   22.490000\n",
      "2025-02-13 14:30:00-05:00  24.680000  24.355000   22.490000\n",
      "2025-02-13 15:30:00-05:00  24.355000  24.110001   22.490000\n",
      "2025-02-14 09:30:00-05:00  24.360001  23.174999   24.110001\n",
      "2025-02-14 10:30:00-05:00  23.172001  23.313801   24.110001\n",
      "2025-02-14 11:30:00-05:00  23.318800  23.280001   24.110001\n",
      "2025-02-14 12:30:00-05:00  23.280001  23.383900   24.110001\n",
      "2025-02-14 13:30:00-05:00  23.385099  23.209999   24.110001\n",
      "2025-02-14 14:30:00-05:00  23.209999  23.680099   24.110001\n",
      "2025-02-14 15:30:00-05:00  23.680799  23.610001   24.110001\n",
      "2025-02-18 09:30:00-05:00  24.605000  26.089899   23.610001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Add a new 'prev_close' column from previous business day and forward fill to next business day hourly\n",
    "# intervals for all the tickers in the multi dimentional data frame\n",
    "\n",
    "# 1. Define the NYSE trading calendar (to handle holidays)\n",
    "nyse = get_calendar('NYSE')\n",
    "trading_days = nyse.schedule(start_date=start_date, end_date=end_date)\n",
    "# Convert to DatetimeIndex\n",
    "trading_days = pd.DatetimeIndex(trading_days.index)\n",
    "holidays = nyse.holidays().holidays  # List of NYSE holidays\n",
    "\n",
    "# Custom business day offset\n",
    "bday = CustomBusinessDay(holidays=holidays)\n",
    "\n",
    "# 2. Adjusted function to calculate prev_close\n",
    "def add_prev_close(df):\n",
    "    # Get daily closing prices (aligned to trading days)\n",
    "    daily_close = df['Close'].resample(bday).last()\n",
    "    # Shift to previous trading day\n",
    "    prev_day_close = daily_close.shift(1)\n",
    "    # Forward-fill to hourly intervals\n",
    "    df['Prev_Close'] = prev_day_close.reindex(df.index, method='ffill')\n",
    "    return df\n",
    "\n",
    "# 3. Process data (no grouping by day)\n",
    "tickers = data.columns.get_level_values(0).unique()\n",
    "processed_dfs = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    df = data[ticker].copy()\n",
    "    # Process entire history (not daily groups)\n",
    "    df = add_prev_close(df)\n",
    "    df.columns = pd.MultiIndex.from_product([[ticker], df.columns])\n",
    "    processed_dfs.append(df)\n",
    "\n",
    "data = pd.concat(processed_dfs, axis=1)\n",
    "\n",
    "# Verify non-NaN results\n",
    "print(data['INTC'][['Open','Close', 'Prev_Close']].head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94a118bd-ad9f-4fab-9084-f53c7a597194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                            Low  Prev_Close Signal\n",
      "Datetime                                               \n",
      "2025-02-06 09:30:00-05:00  19.379999         NaN      N\n",
      "2025-02-06 10:30:00-05:00  19.320000         NaN      N\n",
      "2025-02-06 11:30:00-05:00  19.250000         NaN      N\n",
      "2025-02-06 12:30:00-05:00  19.260000         NaN      N\n",
      "2025-02-06 13:30:00-05:00  19.250000         NaN      N\n",
      "2025-02-06 14:30:00-05:00  19.219999         NaN      N\n",
      "2025-02-06 15:30:00-05:00  19.270000         NaN      N\n",
      "2025-02-07 09:30:00-05:00  19.030001   19.379999      N\n",
      "2025-02-07 10:30:00-05:00  19.059999   19.379999      N\n",
      "2025-02-07 11:30:00-05:00  19.049999   19.379999      N\n",
      "2025-02-07 12:30:00-05:00  19.084801   19.379999      N\n",
      "2025-02-07 13:30:00-05:00  19.059999   19.379999      N\n",
      "2025-02-07 14:30:00-05:00  19.049999   19.379999      N\n",
      "2025-02-07 15:30:00-05:00  19.059999   19.379999      N\n",
      "2025-02-10 09:30:00-05:00  19.240000   19.105000      N\n",
      "2025-02-10 10:30:00-05:00  19.680000   19.105000      N\n",
      "2025-02-10 11:30:00-05:00  19.700001   19.105000      N\n",
      "2025-02-10 12:30:00-05:00  19.830000   19.105000      N\n",
      "2025-02-10 13:30:00-05:00  19.760099   19.105000      N\n",
      "2025-02-10 14:30:00-05:00  19.750000   19.105000      N\n",
      "2025-02-10 15:30:00-05:00  19.680000   19.105000      N\n",
      "2025-02-11 09:30:00-05:00  19.861799   19.760000      N\n",
      "2025-02-11 10:30:00-05:00  20.840000   19.760000      N\n",
      "2025-02-11 11:30:00-05:00  21.230000   19.760000      N\n",
      "2025-02-11 12:30:00-05:00  21.045000   19.760000      N\n",
      "2025-02-11 13:30:00-05:00  21.000000   19.760000      N\n",
      "2025-02-11 14:30:00-05:00  20.969999   19.760000      N\n",
      "2025-02-11 15:30:00-05:00  20.969999   19.760000      N\n",
      "2025-02-12 09:30:00-05:00  20.930000   20.990000      N\n",
      "2025-02-12 10:30:00-05:00  21.285000   20.990000      N\n",
      "2025-02-12 11:30:00-05:00  21.740000   20.990000      N\n",
      "2025-02-12 12:30:00-05:00  21.745001   20.990000      N\n",
      "2025-02-12 13:30:00-05:00  22.115000   20.990000      N\n",
      "2025-02-12 14:30:00-05:00  22.139999   20.990000      N\n",
      "2025-02-12 15:30:00-05:00  22.150000   20.990000      N\n",
      "2025-02-13 09:30:00-05:00  22.790001   22.490000      N\n",
      "2025-02-13 10:30:00-05:00  24.150000   22.490000      N\n",
      "2025-02-13 11:30:00-05:00  24.170000   22.490000      N\n",
      "2025-02-13 12:30:00-05:00  24.290100   22.490000      N\n",
      "2025-02-13 13:30:00-05:00  24.260000   22.490000      N\n",
      "2025-02-13 14:30:00-05:00  24.170000   22.490000      N\n",
      "2025-02-13 15:30:00-05:00  23.920000   22.490000      N\n",
      "2025-02-14 09:30:00-05:00  22.930000   24.110001      N\n",
      "2025-02-14 10:30:00-05:00  22.860001   24.110001      N\n",
      "2025-02-14 11:30:00-05:00  23.180000   24.110001      N\n",
      "2025-02-14 12:30:00-05:00  23.260000   24.110001      N\n",
      "2025-02-14 13:30:00-05:00  23.209999   24.110001      N\n",
      "2025-02-14 14:30:00-05:00  23.064899   24.110001      N\n",
      "2025-02-14 15:30:00-05:00  23.520000   24.110001      N\n",
      "2025-02-18 09:30:00-05:00  24.490999   23.610001      Y\n",
      "2025-02-18 10:30:00-05:00  25.695000   23.610001      Y\n",
      "2025-02-18 11:30:00-05:00  25.639999   23.610001      Y\n",
      "2025-02-18 12:30:00-05:00  25.715000   23.610001      Y\n",
      "2025-02-18 13:30:00-05:00  26.014999   23.610001      Y\n",
      "2025-02-18 14:30:00-05:00  26.469999   23.610001      Y\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Add a new 'Signal' column that will indicate 'Y' if the a ticker's first interval low is greater than x% \n",
    "# of the prev_close and the next 4hr interval lows are all greater than the first interval's low. Else it will be 'N'\n",
    "\n",
    "THRESHOLD_PCT = 0.03  # 5%\n",
    "\n",
    "# Get all tickers from the MultiIndex columns\n",
    "tickers = data.columns.get_level_values(0).unique()\n",
    "\n",
    "# Create a list to hold processed DataFrames\n",
    "processed_dfs = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Get the DataFrame for the current ticker\n",
    "    df = data[ticker].copy()\n",
    "    \n",
    "    # Ensure the index is timezone-aware (NYSE time)\n",
    "    df.index = df.index.tz_convert('America/New_York')\n",
    "    \n",
    "    # Initialize signal column with 'N'\n",
    "    df['Signal'] = 'N'\n",
    "    \n",
    "    # Group by date (using NYSE trading days)\n",
    "    df['date'] = df.index.date\n",
    "    grouped = df.groupby('date')\n",
    "    \n",
    "    for date, group in grouped:\n",
    "        # Skip days with <5 hours or missing prev_close\n",
    "        if len(group) < 5 or group['Prev_Close'].isna().any():\n",
    "            continue\n",
    "            \n",
    "        # Get first hour's low and prev_close\n",
    "        first_low = group['Low'].iloc[0]\n",
    "        prev_close = group['Prev_Close'].iloc[0]\n",
    "        threshold = prev_close * (1 + THRESHOLD_PCT)\n",
    "        \n",
    "        # Condition 1: First low > 5% above prev_close\n",
    "        if first_low > threshold:\n",
    "            # Condition 2: Next 4 lows > first_low\n",
    "            next_4_lows = group['Low'].iloc[1:5]\n",
    "            if (next_4_lows > first_low).all():\n",
    "                # Mark all rows in this day with 'Y'\n",
    "                df.loc[group.index, 'Signal'] = 'Y'\n",
    "    \n",
    "    # Drop temporary 'date' column\n",
    "    df = df.drop(columns=['date'])\n",
    "    \n",
    "    # Rebuild MultiIndex columns for the ticker\n",
    "    df.columns = pd.MultiIndex.from_product([[ticker], df.columns])\n",
    "    processed_dfs.append(df)\n",
    "\n",
    "# Combine all tickers back into the original DataFrame\n",
    "data = pd.concat(processed_dfs, axis=1)\n",
    "\n",
    "# Verify the new column for INTC\n",
    "print(data['INTC'][['Low', 'Prev_Close', 'Signal']].head(55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26f63713-4492-4ca2-b70e-cd40be329cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Signal  Pct_Gain\n",
      "Datetime                                  \n",
      "2025-02-06 09:30:00-05:00      N       NaN\n",
      "2025-02-06 10:30:00-05:00      N       NaN\n",
      "2025-02-06 11:30:00-05:00      N       NaN\n",
      "2025-02-06 12:30:00-05:00      N       NaN\n",
      "2025-02-06 13:30:00-05:00      N       NaN\n",
      "2025-02-06 14:30:00-05:00      N       NaN\n",
      "2025-02-06 15:30:00-05:00      N       NaN\n",
      "2025-02-07 09:30:00-05:00      N       NaN\n",
      "2025-02-07 10:30:00-05:00      N       NaN\n",
      "2025-02-07 11:30:00-05:00      N       NaN\n",
      "2025-02-07 12:30:00-05:00      N       NaN\n",
      "2025-02-07 13:30:00-05:00      N       NaN\n",
      "2025-02-07 14:30:00-05:00      N       NaN\n",
      "2025-02-07 15:30:00-05:00      N       NaN\n",
      "2025-02-10 09:30:00-05:00      N       NaN\n",
      "2025-02-10 10:30:00-05:00      N       NaN\n",
      "2025-02-10 11:30:00-05:00      N       NaN\n",
      "2025-02-10 12:30:00-05:00      N       NaN\n",
      "2025-02-10 13:30:00-05:00      N       NaN\n",
      "2025-02-10 14:30:00-05:00      N       NaN\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Add a new 'Pct_Gain' column that will show the percentage gain calculated for all the tickers, for the days which the \n",
    "# Signal = 'Y' \n",
    "\n",
    "# Get all tickers from MultiIndex columns\n",
    "tickers = data.columns.get_level_values(0).unique()\n",
    "\n",
    "# Create a list to store processed DataFrames\n",
    "processed_dfs = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Get ticker data from MultiIndex\n",
    "    df = data[ticker].copy()\n",
    "    \n",
    "    # Create date column (NYSE timezone-aware)\n",
    "    df['date'] = df.index.tz_convert('America/New_York').date\n",
    "    \n",
    "    # Group by date to calculate daily metrics\n",
    "    daily_metrics = df.groupby('date').agg({\n",
    "        'Open': 'first',\n",
    "        'Close': 'last',\n",
    "        'Signal': lambda x: 'Y' if x.eq('Y').all() else 'N'\n",
    "    })\n",
    "    \n",
    "    # Calculate percentage gain for 'Y' days\n",
    "    daily_metrics['Pct_Gain'] = np.where(\n",
    "        daily_metrics['Signal'] == 'Y',\n",
    "        (daily_metrics['Close'] - daily_metrics['Open']) / daily_metrics['Open'] * 100,\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    # Merge back to hourly data\n",
    "    df = df.merge(\n",
    "        daily_metrics['Pct_Gain'],\n",
    "        left_on='date',\n",
    "        right_index=True,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Cleanup and maintain MultiIndex\n",
    "    df = df.drop(columns=['date'])\n",
    "    df.columns = pd.MultiIndex.from_product([[ticker], df.columns])\n",
    "    processed_dfs.append(df)\n",
    "\n",
    "# Rebuild the entire DataFrame with new structure\n",
    "data = pd.concat(processed_dfs, axis=1)\n",
    "\n",
    "\n",
    "# Verify the new column for INTC\n",
    "print(data['INTC'][['Signal', 'Pct_Gain']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "250721cc-013a-4e5e-a0eb-4a7c0fa0e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 259 matching rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Prev_Close</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Pct_Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-18 09:30:00-05:00</td>\n",
       "      <td>INTC</td>\n",
       "      <td>24.605000</td>\n",
       "      <td>26.240000</td>\n",
       "      <td>24.490999</td>\n",
       "      <td>26.089899</td>\n",
       "      <td>94841484</td>\n",
       "      <td>23.610001</td>\n",
       "      <td>Y</td>\n",
       "      <td>11.48141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-18 10:30:00-05:00</td>\n",
       "      <td>INTC</td>\n",
       "      <td>26.080000</td>\n",
       "      <td>26.209999</td>\n",
       "      <td>25.695000</td>\n",
       "      <td>25.915001</td>\n",
       "      <td>26492202</td>\n",
       "      <td>23.610001</td>\n",
       "      <td>Y</td>\n",
       "      <td>11.48141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-18 11:30:00-05:00</td>\n",
       "      <td>INTC</td>\n",
       "      <td>25.910000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>25.639999</td>\n",
       "      <td>25.714899</td>\n",
       "      <td>22623144</td>\n",
       "      <td>23.610001</td>\n",
       "      <td>Y</td>\n",
       "      <td>11.48141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-18 12:30:00-05:00</td>\n",
       "      <td>INTC</td>\n",
       "      <td>25.715000</td>\n",
       "      <td>26.209999</td>\n",
       "      <td>25.715000</td>\n",
       "      <td>26.150000</td>\n",
       "      <td>15898605</td>\n",
       "      <td>23.610001</td>\n",
       "      <td>Y</td>\n",
       "      <td>11.48141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-18 13:30:00-05:00</td>\n",
       "      <td>INTC</td>\n",
       "      <td>26.150000</td>\n",
       "      <td>26.559700</td>\n",
       "      <td>26.014999</td>\n",
       "      <td>26.555000</td>\n",
       "      <td>26299210</td>\n",
       "      <td>23.610001</td>\n",
       "      <td>Y</td>\n",
       "      <td>11.48141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2025-02-10 11:30:00-05:00</td>\n",
       "      <td>NUE</td>\n",
       "      <td>137.544998</td>\n",
       "      <td>138.570007</td>\n",
       "      <td>137.059998</td>\n",
       "      <td>138.462006</td>\n",
       "      <td>378574</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.57748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2025-02-10 12:30:00-05:00</td>\n",
       "      <td>NUE</td>\n",
       "      <td>138.549896</td>\n",
       "      <td>139.800003</td>\n",
       "      <td>138.369995</td>\n",
       "      <td>138.520004</td>\n",
       "      <td>655846</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.57748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2025-02-10 13:30:00-05:00</td>\n",
       "      <td>NUE</td>\n",
       "      <td>138.520004</td>\n",
       "      <td>139.029999</td>\n",
       "      <td>137.419998</td>\n",
       "      <td>137.699997</td>\n",
       "      <td>412877</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.57748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2025-02-10 14:30:00-05:00</td>\n",
       "      <td>NUE</td>\n",
       "      <td>137.710007</td>\n",
       "      <td>138.500000</td>\n",
       "      <td>137.520004</td>\n",
       "      <td>137.529999</td>\n",
       "      <td>382024</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.57748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2025-02-10 15:30:00-05:00</td>\n",
       "      <td>NUE</td>\n",
       "      <td>137.500000</td>\n",
       "      <td>138.389999</td>\n",
       "      <td>137.199203</td>\n",
       "      <td>137.589996</td>\n",
       "      <td>626840</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.57748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Datetime Ticker        Open        High         Low  \\\n",
       "0   2025-02-18 09:30:00-05:00   INTC   24.605000   26.240000   24.490999   \n",
       "1   2025-02-18 10:30:00-05:00   INTC   26.080000   26.209999   25.695000   \n",
       "2   2025-02-18 11:30:00-05:00   INTC   25.910000   26.250000   25.639999   \n",
       "3   2025-02-18 12:30:00-05:00   INTC   25.715000   26.209999   25.715000   \n",
       "4   2025-02-18 13:30:00-05:00   INTC   26.150000   26.559700   26.014999   \n",
       "..                        ...    ...         ...         ...         ...   \n",
       "254 2025-02-10 11:30:00-05:00    NUE  137.544998  138.570007  137.059998   \n",
       "255 2025-02-10 12:30:00-05:00    NUE  138.549896  139.800003  138.369995   \n",
       "256 2025-02-10 13:30:00-05:00    NUE  138.520004  139.029999  137.419998   \n",
       "257 2025-02-10 14:30:00-05:00    NUE  137.710007  138.500000  137.520004   \n",
       "258 2025-02-10 15:30:00-05:00    NUE  137.500000  138.389999  137.199203   \n",
       "\n",
       "          Close    Volume  Prev_Close Signal  Pct_Gain  \n",
       "0     26.089899  94841484   23.610001      Y  11.48141  \n",
       "1     25.915001  26492202   23.610001      Y  11.48141  \n",
       "2     25.714899  22623144   23.610001      Y  11.48141  \n",
       "3     26.150000  15898605   23.610001      Y  11.48141  \n",
       "4     26.555000  26299210   23.610001      Y  11.48141  \n",
       "..          ...       ...         ...    ...       ...  \n",
       "254  138.462006    378574  130.220001      Y   0.57748  \n",
       "255  138.520004    655846  130.220001      Y   0.57748  \n",
       "256  137.699997    412877  130.220001      Y   0.57748  \n",
       "257  137.529999    382024  130.220001      Y   0.57748  \n",
       "258  137.589996    626840  130.220001      Y   0.57748  \n",
       "\n",
       "[259 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 8: Display all the tickers with days having Signal = 'Y'\n",
    "\n",
    "# Get all tickers with 'signal' column\n",
    "tickers = data.columns.get_level_values(0).unique()\n",
    "\n",
    "# Filter rows where signal is 'Y' for any ticker\n",
    "filtered_rows = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Get rows where current ticker's signal is 'Y'\n",
    "    mask = data[(ticker, 'Signal')] == 'Y'\n",
    "    ticker_y = data[ticker][mask]\n",
    "    \n",
    "    if not ticker_y.empty:\n",
    "        # Add ticker name as column\n",
    "        ticker_y = ticker_y.copy()\n",
    "        ticker_y['Ticker'] = ticker\n",
    "        filtered_rows.append(ticker_y)\n",
    "\n",
    "# Combine all results\n",
    "if filtered_rows:\n",
    "    result_df = pd.concat(filtered_rows).reset_index()\n",
    "    # Reorder columns\n",
    "    cols = ['Datetime', 'Ticker'] + [c for c in result_df.columns if c not in ['Datetime', 'Ticker']]\n",
    "    result_df = result_df[cols]\n",
    "    print(f\"Found {len(result_df)} matching rows:\")\n",
    "    display(result_df)\n",
    "else:\n",
    "    print(\"No rows with signal = 'Y' found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
